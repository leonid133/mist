mist.context-defaults.spark-conf = {
  spark.cores.max = 1500
  spark.mesos.executor.memoryOverhead = 1000
  spark.executor.memory = "8100m"
  spark.ui.port = 4069
  spark.ui.showConsoleProgress = "false"
  spark.eventLog.enabled ="true"
  spark.dynamicAllocation.enabled = "false"
  spark.speculation = "true"
  spark.speculation.interval = "60s"
  spark.broadcast.compress = "true"
  spark.rdd.compress = "true"
  spark.speculation.quantile = "0.01"
  spark.speculation.multiplier = "1.1"
  spark.scheduler.mode = "FAIR"
  spark.dynamicAllocation.executorIdleTimeout = "240s"
  spark.dynamicAllocation.schedulerBacklogTimeout = "1s"
  spark.dynamicAllocation.sustainedSchedulerBacklogTimeout = "1s"
  spark.kryoserializer.buffer.max = "250m"
  spark.default.parallelism = 1000
  spark.sql.shuffle.partitions = 1000
  spark.eventLog.dir ="maprfs://mapr5-002/sas/pca/eventlog/"
}

mist.context.PCA_EP-Create_Ref_Tables.spark-conf = {
  spark.ui.port = 4169

}

mist.context.PCA_EP-filter_IDA_task.spark-conf = {
  spark.ui.port = 4269
}

mist.context.PCA_EP-filter_CA_events_task.spark-conf = {
  spark.speculation = "false"
  spark.ui.port = 4369

}

mist.context.PCA_EP-filter_events_task.spark-conf = {
  spark.speculation = "false"
  spark.ui.port = 4469

}

mist.context.PCA_EP-write_new_events.spark-conf = {
  spark.dynamicAllocation.enabled  = "false"
  spark.speculation = "false"
  spark.task.cpus = "1"
  spark.ui.port = 4569
}

mist.context.PCA_EP-filter_ref_tables.spark-conf = {
  spark.speculation = "false"
  spark.ui.port = 4669
}

mist.context.PCA_EP-PCA_run_task.spark-conf = {
  spark.speculation = "true"
  spark.task.cpus = "1"
  spark.network.timeout = 300000
  spark.memory.fraction = 0.15
  spark.memory.storageFraction = 0.4
  spark.ui.port = 4769
}

mist.context.PCA_EP-output_taskAll.spark-conf = {
  spark.ui.port = 4869
}

mist.context.PCA_EP-EventLogTracking.spark-conf = {
  spark.eventLog.enabled = "false"
  spark.ui.port = 4969
}

mist.context.PCA_EP-TestParaccel.spark-conf = {
  spark.ui.port = 4079
  spark.cores.max = 1500
}


mist.context.PCA_EP-EntryPonitTest.timeout = Inf
mist.context.PCA_EP-EntryPonitTest.spark-conf = {
  spark.ui.port = 4080
}
mist.context.PCA_EP-EntryPonitTestShort.timeout = 1 min
mist.context.PCA_EP-EntryPonitTestShort.spark-conf = {
  spark.ui.port = 4081
}

mist.http.on = true
mist.http.host = "10.21.49.162"
mist.http.port = 2003
mist.http.router-config-path = "configs/router_nd.conf"

mist.mqtt.on = true
mist.mqtt.host = "rabbitmq.9dev.io"
mist.mqtt.port = 1883
mist.mqtt.subscribe-topic = "pca_mist_sub"
mist.mqtt.publish-topic = "pca_mist_pub"

mist.recovery.on = false
mist.recovery.multilimit = 10
mist.recovery.typedb = "MapDb"
mist.recovery.dbfilename = "file.db"

mist.workers.runner = "local" #"local" or "docker"
mist.workers.host = "localhost" # default for unix socker
mist.workers.port = 80

mist.context.context-defaults.timeout = 180 min

mist.context-defaults.disposable = true
mist.context-defaults.worker-downtime = 190 min
mist.context-defaults.run-options = "--packages com.nd.location:api:1.2.9-SNAPSHOT,mysql:mysql-connector-java:6.0.5,com.jiwire:jiwire-grs:3.1.0-SNAPSHOT --exclude-packages com.jiwire:jicore --jars /nethome/lblokhin/jars/postgresql-8.4-703.jdbc3.jar"


mist.akka {
  loglevel = "ERROR"
  loggers = ["akka.event.Logging$DefaultLogger"]
  
  remote {
    log-remote-lifecycle-events = off
    log-recieved-messages = off
    netty.tcp {
      #hostname = "10.21.49.162"
      hostname = "localhost"
    }
    transport-failure-detector {
      heartbeat-interval = 60s
      acceptable-heartbeat-pause = 5s
    }
  }
  
  cluster {
    seed-nodes = ["akka.tcp://mist@localhost:2551"]
    auto-down-unreachable-after = 60s
  }
}

mist.main.akka {
  remote.netty.tcp.port = 2551
}

mist.worker.akka {
  remote.netty.tcp.port = 0
}
